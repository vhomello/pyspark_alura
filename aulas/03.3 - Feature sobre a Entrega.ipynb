{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579478de",
   "metadata": {},
   "source": [
    "# 3.3 - Feature sobre a entrega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97cbd456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "26/02/06 10:15:11 WARN Utils: Your hostname, MacBook-Air-de-Vitor.local, resolves to a loopback address: 127.0.0.1; using 192.168.3.49 instead (on interface en0)\n",
      "26/02/06 10:15:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/06 10:15:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "26/02/06 10:15:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ac68ad",
   "metadata": {},
   "source": [
    "## Carregando CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9e9d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+\n",
      "|            order_id|         customer_id|order_status|order_purchase_timestamp|  order_approved_at|order_delivered_carrier_date|order_delivered_customer_date|order_estimated_delivery_date|\n",
      "+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+\n",
      "|e481f51cbdc54678b...|9ef432eb625129730...|   delivered|     2017-10-02 10:56:33|2017-10-02 11:07:15|         2017-10-04 19:55:00|          2017-10-10 21:25:13|          2017-10-18 00:00:00|\n",
      "|53cdb2fc8bc7dce0b...|b0830fb4747a6c6d2...|   delivered|     2018-07-24 20:41:37|2018-07-26 03:24:27|         2018-07-26 14:31:00|          2018-08-07 15:27:45|          2018-08-13 00:00:00|\n",
      "|47770eb9100c2d0c4...|41ce2a54c0b03bf34...|   delivered|     2018-08-08 08:38:49|2018-08-08 08:55:23|         2018-08-08 13:50:00|          2018-08-17 18:06:29|          2018-09-04 00:00:00|\n",
      "|949d5b44dbf5de918...|f88197465ea7920ad...|   delivered|     2017-11-18 19:28:06|2017-11-18 19:45:59|         2017-11-22 13:39:59|          2017-12-02 00:28:42|          2017-12-15 00:00:00|\n",
      "|ad21c59c0840e6cb8...|8ab97904e6daea886...|   delivered|     2018-02-13 21:18:39|2018-02-13 22:20:29|         2018-02-14 19:46:34|          2018-02-16 18:17:02|          2018-02-26 00:00:00|\n",
      "+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      " |-- order_purchase_timestamp: timestamp (nullable = true)\n",
      " |-- order_approved_at: timestamp (nullable = true)\n",
      " |-- order_delivered_carrier_date: timestamp (nullable = true)\n",
      " |-- order_delivered_customer_date: timestamp (nullable = true)\n",
      " |-- order_estimated_delivery_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"data/raw/olist_orders_dataset.csv\"\n",
    "df = spark.read.csv(path, header=True, inferSchema=True)\n",
    "\n",
    "df.show(5)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da426a8",
   "metadata": {},
   "source": [
    "## Renomeando\n",
    "As colunas tem um nome muito longo, vamos simplificar um pouco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b60f3f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- order_purchase_timestamp: timestamp (nullable = true)\n",
      " |-- order_approved_at: timestamp (nullable = true)\n",
      " |-- order_delivered_carrier_date: timestamp (nullable = true)\n",
      " |-- order_delivered_customer_date: timestamp (nullable = true)\n",
      " |-- order_estimated_delivery_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# usando withColumnRenamed\n",
    "df.withColumnRenamed(\"order_status\", \"status\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aee8e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- purchase_timestamp: timestamp (nullable = true)\n",
      " |-- approved_at: timestamp (nullable = true)\n",
      " |-- delivered_carrier_date: timestamp (nullable = true)\n",
      " |-- delivered_customer_date: timestamp (nullable = true)\n",
      " |-- estimated_delivery_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Temos que aplicar o withColumnRenamed em 6 colunas, vamos automatizar\n",
    "# Removendo order_, menos do order_id\n",
    "# Vamos fazer isso com um loop\n",
    "\n",
    "columns = df.columns\n",
    "n = len(columns)\n",
    "\n",
    "for i in range(n):\n",
    "    if columns[i] == 'order_id':\n",
    "        columns[i] = F.col(columns[i])\n",
    "    elif 'order_' in columns[i]:\n",
    "        columns[i] = F.col(columns[i]).alias(columns[i].replace('order_', ''))\n",
    "    else:\n",
    "        columns[i] = F.col(columns[i])\n",
    "\n",
    "df = df.select(columns)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb78d910",
   "metadata": {},
   "source": [
    "## Criando Variáveis\n",
    "\n",
    "Queremos criar as seguintes variáveis\n",
    "1. Mês da compra\n",
    "2. Semana da compra\n",
    "3. Dia da semana da compra\n",
    "4. Dias entre a compra e a entrega\n",
    "\n",
    "Vocês podem explorar outras variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "834a862d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------+-------------+-----------------+\n",
      "|            order_id| purchase_timestamp|purchase_month|purchase_week|purchase_day_week|\n",
      "+--------------------+-------------------+--------------+-------------+-----------------+\n",
      "|e481f51cbdc54678b...|2017-10-02 10:56:33|            10|           40|                2|\n",
      "|53cdb2fc8bc7dce0b...|2018-07-24 20:41:37|             7|           30|                3|\n",
      "|47770eb9100c2d0c4...|2018-08-08 08:38:49|             8|           32|                4|\n",
      "|949d5b44dbf5de918...|2017-11-18 19:28:06|            11|           46|                7|\n",
      "|ad21c59c0840e6cb8...|2018-02-13 21:18:39|             2|            7|                3|\n",
      "+--------------------+-------------------+--------------+-------------+-----------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Criando as variaveis que extraem informações do dia da compra\n",
    "\n",
    "date_col = \"purchase_timestamp\"\n",
    "\n",
    "(\n",
    "    df\n",
    "    .select(\n",
    "        F.col(\"order_id\"),\n",
    "        F.col(date_col),\n",
    "        F.month(date_col).alias(\"purchase_month\"),\n",
    "        F.weekofyear(date_col).alias(\"purchase_week\"),\n",
    "        F.dayofweek(date_col).alias(\"purchase_day_week\")\n",
    "    )\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b3075e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------------+------------+\n",
      "| purchase_timestamp|delivered_customer_date|days_between|\n",
      "+-------------------+-----------------------+------------+\n",
      "|2017-10-02 10:56:33|    2017-10-10 21:25:13|           8|\n",
      "|2018-07-24 20:41:37|    2018-08-07 15:27:45|          14|\n",
      "|2018-08-08 08:38:49|    2018-08-17 18:06:29|           9|\n",
      "|2017-11-18 19:28:06|    2017-12-02 00:28:42|          14|\n",
      "|2018-02-13 21:18:39|    2018-02-16 18:17:02|           3|\n",
      "+-------------------+-----------------------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Criando a variavel de diff\n",
    "\n",
    "p_ts = \"purchase_timestamp\"\n",
    "d_ts = \"delivered_customer_date\"\n",
    "\n",
    "(\n",
    "    df\n",
    "    .where(F.col(d_ts).isNotNull())\n",
    "    .select(\n",
    "        F.col(p_ts),\n",
    "        F.col(d_ts),\n",
    "        F.date_diff(d_ts, p_ts).alias(\"days_between\")\n",
    "    )\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0db925f",
   "metadata": {},
   "source": [
    "## Unificando Tudo e Salvando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590e3c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/processed/feature_delivery\"\n",
    "p_ts = \"purchase_timestamp\"\n",
    "d_ts = \"delivered_customer_date\"\n",
    "\n",
    "(\n",
    "    df\n",
    "    .where(F.col(d_ts).isNotNull())\n",
    "    .select(\n",
    "        F.col(\"order_id\"),\n",
    "        F.month(p_ts).alias(\"purchase_month\"),\n",
    "        F.weekofyear(p_ts).alias(\"purchase_week\"),\n",
    "        F.dayofweek(p_ts).alias(\"purchase_day_week\"),\n",
    "        F.date_diff(d_ts, p_ts).alias(\"days_between\")\n",
    "    )\n",
    ").write.mode(\"overwrite\").parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba8a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree data/processed/feature_delivery"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

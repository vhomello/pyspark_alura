{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 4.1 - Features de pagamento (part 2) \n",
                "\n",
                "Neste notebook, vamos explorar como realizar agrupamentos e agregações em DataFrames do PySpark. <br>\n",
                "Usaremos o dataset já processado de pagamentos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING: Using incubator modules: jdk.incubator.vector\n",
                        "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
                        "26/02/06 11:37:17 WARN Utils: Your hostname, MacBook-Air-de-Vitor.local, resolves to a loopback address: 127.0.0.1; using 192.168.3.49 instead (on interface en0)\n",
                        "26/02/06 11:37:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
                        "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
                        "Setting default log level to \"WARN\".\n",
                        "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
                        "26/02/06 11:37:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
                    ]
                }
            ],
            "source": [
                "from pyspark.sql import SparkSession\n",
                "from pyspark.sql import functions as F\n",
                "\n",
                "spark = SparkSession.builder.getOrCreate()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+--------------------+------------------+------------+--------------------+-------------+-----------------------+-----------------------------+\n",
                        "|            order_id|payment_sequential|payment_type|payment_installments|payment_value|payment_log_total_value|payment_log_installment_value|\n",
                        "+--------------------+------------------+------------+--------------------+-------------+-----------------------+-----------------------------+\n",
                        "|b81ef226f3fe1789b...|                 1| credit_card|                   8|        99.33|     1.9970804354717304|            1.093990448479787|\n",
                        "|a9810da82917af2d9...|                 1| credit_card|                   1|        24.39|     1.3872118003137304|           1.3872118003137304|\n",
                        "|25e8ea4e93396b6fa...|                 1| credit_card|                   1|        65.71|     1.8176314671905152|           1.8176314671905152|\n",
                        "|ba78997921bbcdc13...|                 1| credit_card|                   8|       107.78|     2.0325381792600066|            1.129448192268063|\n",
                        "|42fdf880ba16b47b5...|                 1| credit_card|                   2|       128.45|      2.108734108602365|           1.8077041129383837|\n",
                        "+--------------------+------------------+------------+--------------------+-------------+-----------------------+-----------------------------+\n",
                        "only showing top 5 rows\n",
                        "root\n",
                        " |-- order_id: string (nullable = true)\n",
                        " |-- payment_sequential: integer (nullable = true)\n",
                        " |-- payment_type: string (nullable = true)\n",
                        " |-- payment_installments: integer (nullable = true)\n",
                        " |-- payment_value: double (nullable = true)\n",
                        " |-- payment_log_total_value: double (nullable = true)\n",
                        " |-- payment_log_installment_value: double (nullable = true)\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "path = \"data/processed/feature_payment\"\n",
                "\n",
                "df = spark.read.parquet(path)\n",
                "df.show(5)\n",
                "df.printSchema()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conferindo se temos id cuplicados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+--------------------+-----+\n",
                        "|            order_id|count|\n",
                        "+--------------------+-----+\n",
                        "|fa65dad1b0e818e3c...|   29|\n",
                        "|ccf804e764ed5650c...|   26|\n",
                        "|285c2e15bebd4ac83...|   22|\n",
                        "|895ab968e7bb0d565...|   21|\n",
                        "|fedcd9f7ccdc8cba3...|   19|\n",
                        "|ee9ca989fc93ba09a...|   19|\n",
                        "|21577126c19bf11a0...|   15|\n",
                        "|4bfcba9e084f46c8e...|   15|\n",
                        "|3c58bffb70dcf45f1...|   14|\n",
                        "|4689b1816de42507a...|   14|\n",
                        "|cf101c3abd3c061ca...|   13|\n",
                        "|4fb76fa13b108a0d0...|   13|\n",
                        "|73df5d6adbeea12c8...|   13|\n",
                        "|6d58638e32674bebe...|   12|\n",
                        "|465c2e1bee4561cb3...|   12|\n",
                        "|c6492b842ac190db8...|   12|\n",
                        "|67d83bd36ec2c7fb5...|   12|\n",
                        "|1a611328643ae1114...|   12|\n",
                        "|1d9a9731b9c10fc9c...|   12|\n",
                        "|d744783ed2ace06ca...|   12|\n",
                        "+--------------------+-----+\n",
                        "only showing top 20 rows\n"
                    ]
                }
            ],
            "source": [
                "# Nosso modelo vai ser construido para prever no nivel de order_id\n",
                "# Ou seja, temos que ter só uma linha de order id\n",
                "\n",
                "(\n",
                "    df\n",
                "    .groupBy(\"order_id\")\n",
                "    .count()\n",
                "    .orderBy(F.col(\"count\").desc())\n",
                ").show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Criando Features fazendo agrupando por order id \n",
                "\n",
                "Aqui calculamos as estatísticas (mínimo, máximo, média e desvio padrão) para as colunas de payment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+--------------------+-------------------+-----------------+-----------------+------------------+------------------+--------------------+\n",
                        "|            order_id|count_payment_value|min_payment_value|max_payment_value| avg_payment_value| sum_payment_value|stddev_payment_value|\n",
                        "+--------------------+-------------------+-----------------+-----------------+------------------+------------------+--------------------+\n",
                        "|bb2d7e3141540afc2...|                  1|            37.15|            37.15|             37.15|             37.15|                NULL|\n",
                        "|85be7c94bcd3f908f...|                  1|            72.75|            72.75|             72.75|             72.75|                NULL|\n",
                        "|8ca5bdac5ebe8f2d6...|                  9|             15.0|            59.08|21.008888888888887|189.07999999999998|  14.654716343590929|\n",
                        "+--------------------+-------------------+-----------------+-----------------+------------------+------------------+--------------------+\n",
                        "only showing top 3 rows\n"
                    ]
                }
            ],
            "source": [
                "col_name = 'payment_value'\n",
                "\n",
                "df_grouped = df.groupBy(\"order_id\").agg(\n",
                "    F.count(col_name).alias(f\"count_{col_name}\"),\n",
                "    F.min(col_name).alias(f\"min_{col_name}\"),\n",
                "    F.max(col_name).alias(f\"max_{col_name}\"),\n",
                "    F.avg(col_name).alias(f\"avg_{col_name}\"),\n",
                "    F.sum(col_name).alias(f\"sum_{col_name}\"),\n",
                "    F.stddev(col_name).alias(f\"stddev_{col_name}\"),\n",
                ")\n",
                "\n",
                "df_grouped.show(3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Analizando o numero de orders com só um payment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+------------------+\n",
                        "| pct_w_one_payment|\n",
                        "+------------------+\n",
                        "|0.9702232502011263|\n",
                        "+------------------+\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Quando temos só uma linha o stddev fica null\n",
                "\n",
                "(\n",
                "    df_grouped\n",
                "    .agg(\n",
                "        F.mean(F.col(\"stddev_payment_value\").isNull().cast(\"int\")).alias(\"pct_w_one_payment\")\n",
                "    )\n",
                ").show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Impacto de valores Nulos no Agg\n",
                "\n",
                "\n",
                "**Como o `agg` lida com null?**\n",
                "\n",
                "As funções de agregação do Spark (`min`, `max`, `mean`, `stddev`) **ignoram** os valores nulos por padrão. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+-----+\n",
                        "|value|\n",
                        "+-----+\n",
                        "|    1|\n",
                        "|    2|\n",
                        "| NULL|\n",
                        "+-----+\n",
                        "\n",
                        "+------------+--------+----------+----------+\n",
                        "|count(value)|count(1)|sum(value)|avg(value)|\n",
                        "+------------+--------+----------+----------+\n",
                        "|           2|       3|         3|       1.5|\n",
                        "+------------+--------+----------+----------+\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "df = spark.createDataFrame([(1,), (2,), (None,)], [\"value\"])\n",
                "\n",
                "df.show()\n",
                "df.agg(\n",
                "    F.count(\"value\"),\n",
                "    F.count(\"*\"),\n",
                "    F.sum(\"value\"),\n",
                "    F.avg(\"value\")\n",
                ").show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Salvando Payment Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "path = \"data/processed/feature_payment_part2\"\n",
                "df_grouped.write.mode(\"overwrite\").parquet(path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1;36mdata/processed/feature_payment_part2\u001b[0m\n",
                        "├── _SUCCESS\n",
                        "├── part-00000-2b2fb310-e7d4-4ab6-9923-049f36001f29-c000.snappy.parquet\n",
                        "├── part-00001-2b2fb310-e7d4-4ab6-9923-049f36001f29-c000.snappy.parquet\n",
                        "├── part-00002-2b2fb310-e7d4-4ab6-9923-049f36001f29-c000.snappy.parquet\n",
                        "├── part-00003-2b2fb310-e7d4-4ab6-9923-049f36001f29-c000.snappy.parquet\n",
                        "├── part-00004-2b2fb310-e7d4-4ab6-9923-049f36001f29-c000.snappy.parquet\n",
                        "└── part-00005-2b2fb310-e7d4-4ab6-9923-049f36001f29-c000.snappy.parquet\n",
                        "\n",
                        "1 directory, 7 files\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "26/02/06 14:25:15 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 903293 ms exceeds timeout 120000 ms\n",
                        "26/02/06 14:25:15 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
                        "26/02/06 14:25:22 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:25:22 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:25:32 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:25:32 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:25:42 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:25:42 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:25:52 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:25:52 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:41:07 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:41:07 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:41:17 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:41:17 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:41:27 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:41:27 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:41:37 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:41:37 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:41:47 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:41:47 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:43:35 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:43:35 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:43:45 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:43:45 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:43:55 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:43:55 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:44:05 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:44:05 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:44:15 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:44:15 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:45:29 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:322)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
                        "\t... 17 more\n",
                        "26/02/06 14:45:29 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:322)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
                        "\t... 17 more\n",
                        "26/02/06 14:45:39 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:45:39 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:45:49 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:45:49 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:45:59 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:45:59 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:47:36 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:322)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
                        "\t... 17 more\n",
                        "26/02/06 14:47:36 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:322)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
                        "\t... 17 more\n",
                        "26/02/06 14:47:46 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:47:46 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:47:56 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:47:56 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:48:06 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:48:06 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:48:16 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:48:16 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:52:29 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:52:29 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:52:39 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:52:39 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:52:49 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:52:49 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:52:59 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:52:59 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:53:09 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:53:09 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:53:19 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:53:19 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:53:29 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:53:29 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:55:07 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:55:07 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:55:17 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:55:17 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:55:27 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:55:27 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:55:37 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:55:37 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:58:56 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:322)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
                        "\t... 17 more\n",
                        "26/02/06 14:58:56 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:322)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
                        "\t... 17 more\n",
                        "26/02/06 14:59:06 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:59:06 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:59:16 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:59:16 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:59:26 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:59:26 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:59:36 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 14:59:36 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:02:31 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:02:31 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:02:41 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:02:41 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:02:51 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:02:51 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:03:01 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:03:01 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:03:11 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:03:11 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:04:53 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:04:53 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:05:03 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:05:03 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:05:13 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:05:13 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:05:23 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:05:23 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:09:24 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:09:24 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:09:34 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:09:34 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:09:44 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:09:44 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:09:54 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:09:54 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:10:04 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:10:04 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:12:19 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:322)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
                        "\t... 17 more\n",
                        "26/02/06 15:12:19 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallbacks(Promise.scala:322)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:176)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:153)\n",
                        "\t... 17 more\n",
                        "26/02/06 15:12:29 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:12:29 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:12:39 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:12:39 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:12:49 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:12:49 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:12:59 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:12:59 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:14:33 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:14:33 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:14:43 WARN Executor: Issue communicating with driver in heartbeater\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
                        "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
                        "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:81)\n",
                        "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:674)\n",
                        "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1363)\n",
                        "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:356)\n",
                        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
                        "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1941)\n",
                        "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
                        "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
                        "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
                        "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\t... 3 more\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:14:43 ERROR Inbox: Ignoring error\n",
                        "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
                        "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:53)\n",
                        "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:359)\n",
                        "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
                        "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
                        "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:132)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:131)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:707)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:706)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:746)\n",
                        "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:141)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:216)\n",
                        "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:76)\n",
                        "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:42)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
                        "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
                        "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
                        "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.3.49:54344\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:151)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:147)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:503)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:537)\n",
                        "\tat scala.concurrent.ExecutionContext$parasitic$.execute(ExecutionContext.scala:222)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:368)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.trySuccess(Promise.scala:99)\n",
                        "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:99)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:228)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:242)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:241)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.run(Promise.scala:517)\n",
                        "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
                        "\tat scala.concurrent.impl.ExecutionContextImpl.execute(ExecutionContextImpl.scala:21)\n",
                        "\tat scala.concurrent.impl.Promise$Transformation.submitWithValue(Promise.scala:462)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.submitWithValue(Promise.scala:371)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete0(Promise.scala:295)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
                        "\tat scala.concurrent.Promise.complete(Promise.scala:57)\n",
                        "\tat scala.concurrent.Promise.complete$(Promise.scala:56)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:104)\n",
                        "\tat scala.concurrent.Promise.success(Promise.scala:91)\n",
                        "\tat scala.concurrent.Promise.success$(Promise.scala:91)\n",
                        "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:104)\n",
                        "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
                        "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
                        "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
                        "\t... 8 more\n",
                        "26/02/06 15:14:43 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n",
                        "----------------------------------------\n",
                        "Exception occurred during processing of request from ('127.0.0.1', 54351)\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.11_2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socketserver.py\", line 318, in _handle_request_noblock\n",
                        "    self.process_request(request, client_address)\n",
                        "    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.11_2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socketserver.py\", line 349, in process_request\n",
                        "    self.finish_request(request, client_address)\n",
                        "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.11_2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socketserver.py\", line 362, in finish_request\n",
                        "    self.RequestHandlerClass(request, client_address, self)\n",
                        "    ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.11_2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socketserver.py\", line 766, in __init__\n",
                        "    self.handle()\n",
                        "    ~~~~~~~~~~~^^\n",
                        "  File \"/Users/vho/alura/pyspark_alura/.venv/lib/python3.13/site-packages/pyspark/accumulators.py\", line 303, in handle\n",
                        "    poll(accum_updates)\n",
                        "    ~~~~^^^^^^^^^^^^^^^\n",
                        "  File \"/Users/vho/alura/pyspark_alura/.venv/lib/python3.13/site-packages/pyspark/accumulators.py\", line 272, in poll\n",
                        "    if self.rfile in r and func():\n",
                        "                           ~~~~^^\n",
                        "  File \"/Users/vho/alura/pyspark_alura/.venv/lib/python3.13/site-packages/pyspark/accumulators.py\", line 276, in accum_updates\n",
                        "    num_updates = read_int(self.rfile)\n",
                        "  File \"/Users/vho/alura/pyspark_alura/.venv/lib/python3.13/site-packages/pyspark/serializers.py\", line 597, in read_int\n",
                        "    raise EOFError\n",
                        "EOFError\n",
                        "----------------------------------------\n"
                    ]
                }
            ],
            "source": [
                "!tree data/processed/feature_payment_part2"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
